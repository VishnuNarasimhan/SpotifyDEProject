# ðŸŽ§ Spotify Data Engineering Project

An end-to-end **data engineering pipeline** built using **Azure Data Factory**, **Databricks (PySpark)**, **Delta Lake**, and **Jinja** for dynamic configuration and automation.

---

## ðŸ§­ Overview

This project replicates a **Spotify-style data platform**, where raw data flows through **Bronze â†’ Silver â†’ Gold** layers.  
It covers **data ingestion, transformation, and modeling**, showcasing real-world data engineering practices using Azure tools.

---

## ðŸ§° Tech Stack

- **Azure Data Factory (ADF)** â€“ Orchestrates data movement and pipeline scheduling  
- **Azure Databricks (PySpark)** â€“ Performs transformation and data modeling  
- **Azure Data Lake Storage (ADLS Gen2)** â€“ Stores raw, processed, and curated data  
- **Delta Lake** â€“ Provides ACID transactions, schema enforcement, and time travel  
- **Jinja** â€“ Used for parameterized and reusable PySpark scripts  
- **Languages:** Python, SQL, JSON  

---

## ðŸ“ Folder Structure
spotify-data-engineering-project/
â”‚
â”œâ”€â”€ adf/ # Azure Data Factory pipelines and configs
â”‚ â”œâ”€â”€ factory/
â”‚ â”œâ”€â”€ pipeline/
â”‚ â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ linkedService/
â”‚ â””â”€â”€ publish_config.json
â”‚
â”œâ”€â”€ databricks/ # Databricks notebooks and PySpark scripts
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â””â”€â”€ silver/
â”‚ â”‚ â””â”€â”€ silver_dimensions.py
â”‚ â””â”€â”€ notebooks/
|
â””â”€â”€ README.md

---

## ðŸ”„ Data Pipeline Flow

### 1ï¸âƒ£ Ingestion (Bronze)
- Raw Spotify-like data (users, tracks, streams) is ingested via ADF.  
- Stored in ADLS in Parquet/JSON format.

### 2ï¸âƒ£ Transformation (Silver)
- Databricks reads Bronze data and cleans it using **PySpark** with **Jinja templates**.  
- Generates structured Delta tables:  
  - `DimUser`  
  - `DimTrack`  
  - `FactStream`

### 3ï¸âƒ£ Modeling (Gold)
- Aggregates and models the processed data for analytics and reporting.  
- Data is written back to ADLS in **Delta format** supporting **time travel** and ACID reliability.

---

## âœ¨ Key Features

- End-to-end orchestration with **ADF â†” Databricks** integration  
- Modular and reusable PySpark code built with **Jinja templating**  
- Reliable data storage with **Delta Lake** (ACID + time travel)  
- Follows **Bronzeâ€“Silverâ€“Gold** architecture for clarity and scalability  
- Clean project structure ready for portfolio or production reference

---

## ðŸ“Š Deliverables

- **ADF pipelines:** Automated ingestion and Databricks triggers  
- **Curated Delta tables:** `DimUser`, `DimTrack`, and `FactStream`  
- **Reusable Jinja templates:** For configurable PySpark transformations  
- **Docs and screenshots:** Architecture visuals and pipeline runs  

---

> âš¡ *A clean, production-style Data Engineering project showing how ADF, Databricks, Delta Lake, and Jinja work together to build scalable ETL pipelines.*

